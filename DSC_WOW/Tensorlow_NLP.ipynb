{
 "cells": [
  {
   "source": [
    "Dataset :- https://www.kaggle.com/rmisra/news-category-dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description       date  \n",
       "0  She left her husband. He killed their children... 2018-05-26  \n",
       "1                           Of course it has a song. 2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('News_Category_Dataset_v2.json', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['TF'] = np.where(df['category']  == 'CRIME', 1, np.where(df['category']=='WEIRD NEWS',1,np.where(df['category']=='WOMEN',1,0)))\n",
    "#df['TF'] = np.where(df['category']=='WEIRD NEWS' ,1,0)\n",
    "#df['TF'] = np.where(df['category']=='WOMEN',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=df['headline']\n",
    "labels=df['TF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200853, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = sentences[0:18419]\n",
    "testing_sentences = sentences[18419:]\n",
    "training_labels = labels[0:18419]\n",
    "testing_labels = labels[18419:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 16)           16000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 16,289\n",
      "Trainable params: 16,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "576/576 [==============================] - 10s 18ms/step - loss: 0.3231 - accuracy: 0.9257 - val_loss: 0.1872 - val_accuracy: 0.9544\n",
      "Epoch 2/30\n",
      "576/576 [==============================] - 9s 16ms/step - loss: 0.2443 - accuracy: 0.9326 - val_loss: 0.1857 - val_accuracy: 0.9544\n",
      "Epoch 3/30\n",
      "576/576 [==============================] - 9s 16ms/step - loss: 0.2406 - accuracy: 0.9326 - val_loss: 0.1856 - val_accuracy: 0.9544\n",
      "Epoch 4/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.2349 - accuracy: 0.9326 - val_loss: 0.1850 - val_accuracy: 0.9544\n",
      "Epoch 5/30\n",
      "576/576 [==============================] - 9s 16ms/step - loss: 0.2261 - accuracy: 0.9326 - val_loss: 0.1890 - val_accuracy: 0.9544\n",
      "Epoch 6/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.2148 - accuracy: 0.9329 - val_loss: 0.1817 - val_accuracy: 0.9546\n",
      "Epoch 7/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.2026 - accuracy: 0.9345 - val_loss: 0.1780 - val_accuracy: 0.9549\n",
      "Epoch 8/30\n",
      "576/576 [==============================] - 10s 18ms/step - loss: 0.1927 - accuracy: 0.9345 - val_loss: 0.1779 - val_accuracy: 0.9549\n",
      "Epoch 9/30\n",
      "576/576 [==============================] - 14s 24ms/step - loss: 0.1859 - accuracy: 0.9352 - val_loss: 0.1683 - val_accuracy: 0.9550\n",
      "Epoch 10/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1807 - accuracy: 0.9360 - val_loss: 0.1974 - val_accuracy: 0.9543\n",
      "Epoch 11/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1775 - accuracy: 0.9368 - val_loss: 0.1741 - val_accuracy: 0.9551\n",
      "Epoch 12/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1747 - accuracy: 0.9373 - val_loss: 0.1733 - val_accuracy: 0.9551\n",
      "Epoch 13/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1734 - accuracy: 0.9375 - val_loss: 0.1862 - val_accuracy: 0.9537\n",
      "Epoch 14/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1715 - accuracy: 0.9375 - val_loss: 0.1710 - val_accuracy: 0.9549\n",
      "Epoch 15/30\n",
      "576/576 [==============================] - 14s 24ms/step - loss: 0.1696 - accuracy: 0.9372 - val_loss: 0.1697 - val_accuracy: 0.9549\n",
      "Epoch 16/30\n",
      "576/576 [==============================] - 9s 16ms/step - loss: 0.1690 - accuracy: 0.9388 - val_loss: 0.1931 - val_accuracy: 0.9519\n",
      "Epoch 17/30\n",
      "576/576 [==============================] - 9s 16ms/step - loss: 0.1680 - accuracy: 0.9394 - val_loss: 0.1783 - val_accuracy: 0.9539\n",
      "Epoch 18/30\n",
      "576/576 [==============================] - 14s 24ms/step - loss: 0.1674 - accuracy: 0.9385 - val_loss: 0.1757 - val_accuracy: 0.9542\n",
      "Epoch 19/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1660 - accuracy: 0.9389 - val_loss: 0.1843 - val_accuracy: 0.9528\n",
      "Epoch 20/30\n",
      "576/576 [==============================] - 10s 18ms/step - loss: 0.1651 - accuracy: 0.9399 - val_loss: 0.2059 - val_accuracy: 0.9482\n",
      "Epoch 21/30\n",
      "576/576 [==============================] - 9s 16ms/step - loss: 0.1643 - accuracy: 0.9388 - val_loss: 0.2288 - val_accuracy: 0.9415\n",
      "Epoch 22/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1643 - accuracy: 0.9395 - val_loss: 0.1842 - val_accuracy: 0.9523\n",
      "Epoch 23/30\n",
      "576/576 [==============================] - 9s 16ms/step - loss: 0.1635 - accuracy: 0.9386 - val_loss: 0.1912 - val_accuracy: 0.9510\n",
      "Epoch 24/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1640 - accuracy: 0.9384 - val_loss: 0.2152 - val_accuracy: 0.9454\n",
      "Epoch 25/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1632 - accuracy: 0.9381 - val_loss: 0.1940 - val_accuracy: 0.9506\n",
      "Epoch 26/30\n",
      "576/576 [==============================] - 10s 18ms/step - loss: 0.1628 - accuracy: 0.9383 - val_loss: 0.1999 - val_accuracy: 0.9493\n",
      "Epoch 27/30\n",
      "576/576 [==============================] - 11s 18ms/step - loss: 0.1620 - accuracy: 0.9386 - val_loss: 0.1836 - val_accuracy: 0.9528\n",
      "Epoch 28/30\n",
      "576/576 [==============================] - 10s 17ms/step - loss: 0.1631 - accuracy: 0.9382 - val_loss: 0.1824 - val_accuracy: 0.9531\n",
      "Epoch 29/30\n",
      "576/576 [==============================] - 11s 19ms/step - loss: 0.1623 - accuracy: 0.9396 - val_loss: 0.1990 - val_accuracy: 0.9493\n",
      "Epoch 30/30\n",
      "576/576 [==============================] - 9s 16ms/step - loss: 0.1622 - accuracy: 0.9391 - val_loss: 0.1826 - val_accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = tokenizer.texts_to_sequences([\"Ram killed the innocent\"])\n",
    "key = pad_sequences(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9389\n",
      "Testing Accuracy:  0.9531\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(training_padded, training_labels, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(testing_padded, testing_labels, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"embedding_input:0\", shape=(None, 100), dtype=float32), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.95639515]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GoogleNews import GoogleNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gn = GoogleNews('India')\n",
    "gn.set_lang('en')\n",
    "gn.search('Chennai Theft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=gn.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"embedding_input:0\", shape=(None, 100), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "['Gang stealing Royal Enfield bikes in Chennai arrested']  - >  [[0.9979756]]\n",
      "['100 kg gold ‘vanishes into thin air’ from CBI custody']  - >  [[0.00892904]]\n",
      "['Chennai: This ‘Bullet’ cannot be dodged']  - >  [[0.98456514]]\n",
      "['Projectors worth over ₹15 lakh stolen from Anna University']  - >  [[0.00053397]]\n",
      "['Gold jewellery stolen from PWD official’s home in Thanjavur']  - >  [[0.7598971]]\n",
      "[\"Chennai Brothers Held for Stealing Goats to Fund Father's Movie Starring Them in Lead Roles\"]  - >  [[8.052699e-07]]\n",
      "['New norms reduce cab fare, increase safety']  - >  [[0.00044468]]\n",
      "['Chairman, manager of private hospital held in Coimbatore']  - >  [[0.01386097]]\n",
      "['Tamil Nadu: ‘Intoxicated’ man drives off with government bus as driver checks its tyres']  - >  [[8.4828185e-05]]\n",
      "['Chennai businessman complains of theft of ₹45 lakh from his home']  - >  [[0.91410005]]\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    txt=[str(i['title'])]\n",
    "    txt=np.array(txt)\n",
    "    key = tokenizer.texts_to_sequences(txt)\n",
    "    key = pad_sequences(key)\n",
    "    if txt != ['']:\n",
    "        print(txt,\" - > \",model.predict(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_news1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}